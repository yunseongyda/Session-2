---
marp: true
footer: Created by fls2134
paginate: true
theme: gaia
style: |
  section{background:rgb(241, 237, 234)}
  p{font-size:24px;}
  li{font-size:18pt}
  h1{font-size:28pt}
  h2{font-size:24pt;font-weight:normal}
  h4{font-size:22pt}
  h6{font-size:20pt}
  table{font-size:20px;}
---

# 2ì£¼ì°¨

## ë°ì´í„° ë¶„ì„ê³¼ ìˆ˜ì¹˜ í•´ì„

---

# AI ê°œìš”

- **AI** : ì¸ê°„ì˜ í•™ìŠµ, ì¶”ë¡ , ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì„ ëª¨ë°©í•˜ëŠ” ëª¨ë“  ê¸°ìˆ ì„ í¬í•¨
- âœ… **ML** : ë°ì´í„°ë¥¼ í•™ìŠµí•˜ì—¬ íŒ¨í„´ì„ ì°¾ì•„ ì˜ˆì¸¡í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜
- **DL** : ì¸ê³µì‹ ê²½ë§(Neural Network)ì„ ì´ìš©í•´ ë°ì´í„° í•™ìŠµ

```
ë”¥ëŸ¬ë‹ âŠ‚ ë¨¸ì‹ ëŸ¬ë‹ âŠ‚ ì¸ê³µì§€ëŠ¥
```

---

# MLê³¼ DL êµ¬ë¶„

| êµ¬ë¶„              | ë¨¸ì‹ ëŸ¬ë‹ (Machine Learning)                          | ë”¥ëŸ¬ë‹ (Deep Learning)                          |
| ----------------- | ---------------------------------------------------- | ----------------------------------------------- |
| **ì •ì˜**          | ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµí•˜ëŠ” AI ê¸°ë²•                   | ì‹ ê²½ë§(Neural Network) ê¸°ë°˜ì˜ í•™ìŠµ              |
| **íŠ¹ì§•**          | ë°ì´í„°ì—ì„œ íŒ¨í„´ì„ ì°¾ì•„ ì˜ˆì¸¡                          | ë‹¤ì¸µ ì‹ ê²½ë§ì„ ì‚¬ìš©í•˜ì—¬ ìë™ìœ¼ë¡œ íŠ¹ì§• ì¶”ì¶œ       |
| **ë°ì´í„° ì˜ì¡´ì„±** | â†“                                                    | â†‘                                               |
| **í•™ìŠµ ì†ë„**     | ë¹ ë¦„                                                 | ëŠë¦¼                                            |
| **ëª¨ë¸ ì˜ˆì‹œ**     | SVM, ëœë¤ í¬ë ˆìŠ¤íŠ¸, KNN, ì„ í˜• íšŒê·€, ë¡œì§€ìŠ¤í‹± íšŒê·€ ë“± | CNN, RNN, LSTM, GAN, Transformer ë“±             |
| **ì‘ìš© ë¶„ì•¼**     | ì¶”ì²œ ì‹œìŠ¤í…œ, ì§ˆë³‘ ì˜ˆì¸¡, ê¸ˆìœµ ëª¨ë¸ë§                  | ì´ë¯¸ì§€ ì¸ì‹, ìŒì„± ì¸ì‹, ììœ¨ì£¼í–‰, ë²ˆì—­, ìƒì„± AI |

---

# Neural Network

![height:450](img/image.png)

---

# ì¸ê³µì§€ëŠ¥ í•™ìŠµ(ì‹ ê²½ë§)ê³¼ì •ì˜ ê°œìš”

![height:450](img/sample-0.jpg)

---

# ì§€ë„ & ë¹„ì§€ë„ í•™ìŠµ êµ¬ë¶„

GANì´ë‚˜ ê°•í™”í•™ìŠµ ë“± DLì„ì—ë„ ì§€ë„í•™ìŠµì´ ì•„ë‹Œ ê²½ìš° ì¡´ì¬

| êµ¬ë¶„            | ì§€ë„í•™ìŠµ (Supervised Learning)                                          | ë¹„ì§€ë„í•™ìŠµ (Unsupervised Learning)                 |
| --------------- | ----------------------------------------------------------------------- | -------------------------------------------------- |
| **ì •ì˜**        | ì •ë‹µ(ë¼ë²¨)ì´ ìˆëŠ” ë°ì´í„°ë¥¼ í•™ìŠµ                                         | ì •ë‹µ(ë¼ë²¨) ì—†ì´ ë°ì´í„°ë¥¼ í•™ìŠµ                      |
| **ëª©ì **        | ì…ë ¥ ë°ì´í„°ë¥¼ ë³´ê³  ì •ë‹µì„ ì˜ˆì¸¡                                          | ë°ì´í„°ì˜ ìˆ¨ê²¨ì§„ íŒ¨í„´ì„ ì°¾ìŒ                        |
| **ì…ë ¥ ë°ì´í„°** | (ì…ë ¥ê°’, ì •ë‹µ) ìŒì´ ì¡´ì¬                                                | ì…ë ¥ê°’ë§Œ ì¡´ì¬ (ì •ë‹µ ì—†ìŒ)                          |
| **ì¶œë ¥ ê°’**     | íŠ¹ì • ë¼ë²¨(ë¶„ë¥˜) ë˜ëŠ” ìˆ˜ì¹˜ ê°’(íšŒê·€) ì˜ˆì¸¡                                 | ê·¸ë£¹(í´ëŸ¬ìŠ¤í„°) í• ë‹¹ ë˜ëŠ” íŒ¨í„´ ë°œê²¬                 |
| **ëŒ€í‘œ ëª¨ë¸**   | KNN, SVM, ê²°ì • íŠ¸ë¦¬, ëœë¤ í¬ë ˆìŠ¤íŠ¸, ì„ í˜• íšŒê·€, ë¡œì§€ìŠ¤í‹± íšŒê·€, ì‹ ê²½ë§ ë“± | K-Means, DBSCAN, PCA, êµ°ì§‘ ë¶„ì„, ì—°ê´€ ê·œì¹™ ë¶„ì„ ë“± |
| **ì˜ˆì œ**        | ìŠ¤íŒ¸ ë©”ì¼ ë¶„ë¥˜, ì†ê¸€ì”¨ ìˆ«ì ì¸ì‹, ê°€ê²© ì˜ˆì¸¡                             | ê³ ê° ì„¸ë¶„í™”, ì´ìƒ íƒì§€, ì¶”ì²œ ì‹œìŠ¤í…œ                |

---

# ê²°ë¡ 

```
âœ… í™•ë¥  + ê¸°í•˜
```

![height:360](img/sample-2.png)

---

# Data Analysis

## MLì„ ìœ„í•œ ë°ì´í„° ë¶„ì„ê³¼ ìˆ˜ì¹˜í•´ì„

---

# ë°ì´í„° ë¶„ì„ ìˆ˜ìš”

![height:500](img/sample-1.png)

---

# ëª©ì°¨

<hr/>

1. MLì˜ 4ëŒ€ ì£¼ìš” ëª©ì 
2. ë°ì´í„° ìˆ˜ì¹˜í™” & ì‹œê°í™” ëŒ€í‘œ ë¼ì´ë¸ŒëŸ¬ë¦¬
3. ë¶„ë¥˜
4. í´ëŸ¬ìŠ¤í„°ë§(êµ°ì§‘í™”)
5. ì˜ˆì¸¡

---

<style scoped>section{text-align: center;}</style>

# MLì˜ 4ëŒ€ ì£¼ìš” ëª©ì 

<br/>

## ì˜ˆì¸¡, ë¶„ë¥˜, êµ°ì§‘í™”, ì°¨ì›ì¶•ì†Œ

---

# MLì˜ 4ëŒ€ ì£¼ìš” ëª©ì (1) - ì˜ˆì¸¡

## `ì—°ì†ì  ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡`

###### ì˜ˆì‹œ

- ì£¼ê°€ ì˜ˆì¸¡
- ë‚ ì”¨ ì˜ˆì¸¡
- íŒë§¤ëŸ‰ ì˜ˆì¸¡

###### ëŒ€í‘œ ëª¨ë¸

- ì„ í˜• íšŒê·€ (Linear Regression)
- ëœë¤ í¬ë ˆìŠ¤íŠ¸
- RNN, LSTM (ì‹œê³„ì—´ ë°ì´í„°)

---

# MLì˜ 4ëŒ€ ì£¼ìš” ëª©ì (2) - ë¶„ë¥˜

## `ì£¼ë¡œ True / Falseì— ëŒ€í•œ ë¶„ë¥˜`

###### ì˜ˆì‹œ

- ì´ë¯¸ì§€ êµ¬ë¶„
- ì˜ë£Œ ì§„ë‹¨

###### ëŒ€í‘œ ëª¨ë¸

- KNN (K-Nearest Neighbors)
- SVM (Support Vector Machine)
- CNN (Convolutional Neural Network)

---

# MLì˜ 4ëŒ€ ì£¼ìš” ëª©ì (3) - êµ°ì§‘í™”

## `ë¹„ìŠ·í•œ ë°ì´í„°ë¼ë¦¬ êµ°ì§‘í™”`

###### ì˜ˆì‹œ

- ê³ ê° ì„¸ë¶„í™”
- ë‰´ìŠ¤ ê¸°ì‚¬ ìë™ ë¶„ë¥˜
- ì´ìƒ íƒì§€

###### ëŒ€í‘œ ëª¨ë¸

- K-Means
- DBSCAN
- ê³„ì¸µì  êµ°ì§‘í™”

---

# MLì˜ 4ëŒ€ ì£¼ìš” ëª©ì (4) - ì°¨ì› ì¶•ì†Œ

## `ë°ì´í„°ì—ì„œ ê´€ì‹¬ íŠ¹ì§• ì¶”ì¶œ`

###### ì˜ˆì‹œ

- ë°ì´í„° ì‹œê°í™”
- ë…¸ì´ì¦ˆ ì œê±°

###### ëŒ€í‘œ ëª¨ë¸

- PCA (Principal Component Analysis)
- t-SNE (t-Distributed Stochastic Neighbor Embedding)

---

<style scoped>section{text-align: center;}</style>

# ë°ì´í„° ìˆ˜ì¹˜í™” & ì‹œê°í™” ëŒ€í‘œ ë¼ì´ë¸ŒëŸ¬ë¦¬

<br/>

## Numpy, Pandas, Matplotlib

---

# ë°ì´í„° ìˆ˜ì¹˜í™” & ì‹œê°í™” ëŒ€í‘œ ë¼ì´ë¸ŒëŸ¬ë¦¬(1)

## `Numpy`

ë‹¤ì°¨ì› ë°°ì—´(Matrix)ì˜ ë¹ ë¥¸ ì—°ì‚°

**âœ… í™œìš© ë¶„ì•¼**

- í–‰ë ¬ ì—°ì‚°
- ë°ì´í„° ì „ì²˜ë¦¬
- í†µê³„ ë¶„ì„

---

# ë°ì´í„° ìˆ˜ì¹˜í™” & ì‹œê°í™” ëŒ€í‘œ ë¼ì´ë¸ŒëŸ¬ë¦¬(2)

## `Pandas`

ë°ì´í„°ì— ëŒ€í•œ í‘œ í˜•ì‹ì˜ í‘œí˜„

**âœ… í™œìš© ë¶„ì•¼**

- ë°ì´í„° ë¶„ì„ (ex. ê³ ê° ë°ì´í„° ë¶„ì„)
- ë°ì´í„° ì •ì œ ë° ë³€í™˜
- ë¨¸ì‹ ëŸ¬ë‹ ë°ì´í„° ì¤€ë¹„

---

# ë°ì´í„° ìˆ˜ì¹˜í™” & ì‹œê°í™” ëŒ€í‘œ ë¼ì´ë¸ŒëŸ¬ë¦¬(3)

## `Matplotlib`

ë°ì´í„° ê·¸ë˜í”„ ì‹œê°í™” ì²˜ë¦¬

**âœ… í™œìš© ë¶„ì•¼**

- ë¶„ì„ ì‹œê°í™”
- AI í•™ìŠµ ì‹œ ê³¼ì • ì‹œê°í™”
- í†µê³„ ë°ì´í„° í‘œí˜„

---

# ì‹¤ìŠµ ì „ ì¤€ë¹„

1. Github Repo Fork
2. Repo URL Clone

![height:390](img/image-0.png)

---

3. Colab ì ‘ì† ë° ì£¼ì†Œ ì—°ë™ `ì €ì¥ì†Œ ì´ë¦„ í™•ì¸!`

![height:420](img/image-4.png)

---

4. Create File
5. ì½”ë“œ ì‘ì„±

```py
# write your code

"""
Lorem Ipsum is simply dummy text of the printing and typesetting industry.
Lorem Ipsum has been the industry's standard dummy text ever since the 1500s
when an unknown printer took a galley of type and scrambled it to make a type specimen book
"""

print("Hello World!")

```

---

6. ì‘ì—… ë‚´ìš© ì €ì¥

![height:420](img/image-2.png)

---

7. github ì—°ë™ `ì €ì¥ì†Œ ì´ë¦„ í™•ì¸!`

![height:420](img/image-3.png)

---

8. ìŠ¹ì¸

![height:420](img/image-1.png)

---

# ğŸ·ï¸ Numpy ê¸°ë³¸ ì‚¬ìš©(1)

```py
import numpy as np

# NumPy ë°°ì—´ ìƒì„± (ê¸°ë³¸ì ì¸ ë¦¬ìŠ¤íŠ¸ ë³€í™˜)
arr = np.array([1, 2, 3, 4, 5])
print("1D ë°°ì—´:", arr)

# 2ì°¨ì› ë°°ì—´ (í–‰ë ¬) ìƒì„±
matrix = np.array([[1, 2, 3], [4, 5, 6]])
print("2D ë°°ì—´:\n", matrix)

# ë°°ì—´ì˜ ê¸°ë³¸ ì •ë³´ í™•ì¸
print("ë°°ì—´ í¬ê¸°:", matrix.shape)  # (2,3) â†’ 2í–‰ 3ì—´
print("ë°°ì—´ ì°¨ì›:", matrix.ndim)   # 2ì°¨ì› ë°°ì—´
print("ë°°ì—´ ë°ì´í„° íƒ€ì…:", matrix.dtype)  # int64 (or int32)
```

---

# ğŸ·ï¸ Numpy ê¸°ë³¸ ì‚¬ìš©(2)

```py
# ë‚œìˆ˜ ìƒì„±
random_arr = np.random.rand(3, 3)  # 3x3 ëœë¤ í–‰ë ¬ (0~1 ì‚¬ì´ ê°’)
print("ëœë¤ ë°°ì—´:\n", random_arr)

# ê¸°ë³¸ ì—°ì‚° (ë²¡í„° ì—°ì‚° ê°€ëŠ¥)
a = np.array([10, 20, 30])
b = np.array([1, 2, 3])

print("ë§ì…ˆ:", a + b)  # [11 22 33]
print("ê³±ì…ˆ:", a * b)  # [10 40 90]
```

---

# ğŸ·ï¸ Numpy ê¸°ë³¸ ì‚¬ìš©(3)

```py
# í–‰ë ¬ ê³±ì…ˆ (dot product)
A = np.array([[1, 2], [3, 4]])
B = np.array([[5, 6], [7, 8]])

print("í–‰ë ¬ ê³± (A @ B):\n", A @ B)  # ë˜ëŠ” np.dot(A, B)

# í†µê³„ ì—°ì‚°
data = np.array([10, 20, 30, 40, 50])
print("í‰ê· :", np.mean(data))  # 30.0
print("í‘œì¤€í¸ì°¨:", np.std(data))  # 14.14
print("ìµœëŒ“ê°’:", np.max(data))  # 50
print("ìµœì†Ÿê°’:", np.min(data))  # 10
```

---

# ğŸ  Pandas ê¸°ë³¸ ì‚¬ìš©(1)

```py
import pandas as pd  # Pandas ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°

# 1ï¸âƒ£ ë°ì´í„°í”„ë ˆì„(DataFrame) ìƒì„±
data = {
    'Name': ['Alice', 'Bob', 'Charlie'],
    'Age': [25, 30, 35],
    'Score': [85, 90, 95]
}
df = pd.DataFrame(data)

print("ğŸ“Œ ë°ì´í„°í”„ë ˆì„ ì¶œë ¥:")
print(df)
```

---

# ğŸ  Pandas ê¸°ë³¸ ì‚¬ìš©(2)

```py

# 2ï¸âƒ£ ë°ì´í„°í”„ë ˆì„ ê¸°ë³¸ ì •ë³´ í™•ì¸
print("\nğŸ“Œ ë°ì´í„°í”„ë ˆì„ ì •ë³´:")
print(df.info())  # ë°ì´í„° íƒ€ì…, ê²°ì¸¡ì¹˜ í™•ì¸

print("\nğŸ“Œ ë°ì´í„°í”„ë ˆì„ í†µê³„ ìš”ì•½:")
print(df.describe())  # í‰ê· , í‘œì¤€í¸ì°¨, ìµœì†Œ/ìµœëŒ€ê°’ ë“±

# 3ï¸âƒ£ íŠ¹ì • ì—´ ì„ íƒ
print("\nğŸ“Œ 'Name' ì—´ë§Œ ì„ íƒ:")
print(df['Name'])
```

---

# ğŸ  Pandas ê¸°ë³¸ ì‚¬ìš©(3)

```py

# 4ï¸âƒ£ íŠ¹ì • í–‰ ì„ íƒ (iloc: ì¸ë±ìŠ¤ ê¸°ì¤€, loc: ì´ë¦„ ê¸°ì¤€)
print("\nğŸ“Œ ì²« ë²ˆì§¸ í–‰ ì„ íƒ (iloc ì‚¬ìš©):")
print(df.iloc[0])  # ì²« ë²ˆì§¸ í–‰

print("\nğŸ“Œ 'Bob'ì´ í¬í•¨ëœ í–‰ ì„ íƒ (loc ì‚¬ìš©):")
print(df.loc[df['Name'] == 'Bob'])

# 5ï¸âƒ£ ìƒˆë¡œìš´ ì—´ ì¶”ê°€
df['Passed'] = df['Score'] > 88  # 88ì  ì´ìƒì´ë©´ True
print("\nğŸ“Œ 'Passed' ì—´ ì¶”ê°€:")
print(df)
```

---

# ğŸ  Pandas ê¸°ë³¸ ì‚¬ìš©(4)

```py
# 6ï¸âƒ£ í‰ê·  ë‚˜ì´ ê³„ì‚°
print("\nğŸ“Œ í‰ê·  ë‚˜ì´:", df['Age'].mean())

# 7ï¸âƒ£ ë°ì´í„° ì •ë ¬ (Score ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ)
df_sorted = df.sort_values(by='Score', ascending=False)
print("\nğŸ“Œ ì ìˆ˜ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬:")
print(df_sorted)

# 8ï¸âƒ£ CSV íŒŒì¼ ì €ì¥ ë° ë¶ˆëŸ¬ì˜¤ê¸° (ì‹¤ì œ ì‚¬ìš© ì˜ˆ)
# df.to_csv("data.csv", index=False)  # ì €ì¥
# df = pd.read_csv("data.csv")  # ë¶ˆëŸ¬ì˜¤ê¸°
```

---

# ğŸ‡ matplotlib ê¸°ë³¸ ì‚¬ìš©(1)

```py
import matplotlib.pyplot as plt
import numpy as np

# ì„  ê·¸ë˜í”„ (Line Plot)
x = np.linspace(0, 10, 100)
y = np.sin(x)
plt.plot(x, y, label="sin(x)", color="b", linestyle="--")
plt.title("Sinusoidal Wave")
plt.xlabel("X-axis")
plt.ylabel("Y-axis")
plt.legend()
plt.grid(True)
plt.show()
```

---

# ğŸ‡ matplotlib ê¸°ë³¸ ì‚¬ìš©(2)

```py
# ë§‰ëŒ€ ê·¸ë˜í”„ (Bar Chart)
categories = ["A", "B", "C", "D"]
values = [10, 20, 15, 30]
plt.bar(categories, values, color=['red', 'blue', 'green', 'purple'])
plt.title("Bar Chart Example")
plt.xlabel("Categories")
plt.ylabel("Values")
plt.show()
```

---

# ğŸ‡ matplotlib ê¸°ë³¸ ì‚¬ìš©(3)

```py
# ì‚°ì ë„ (Scatter Plot)
np.random.seed(0)
x = np.random.rand(50)
y = np.random.rand(50)
colors = np.random.rand(50)
plt.scatter(x, y, c=colors, cmap='viridis', alpha=0.7, edgecolors="black")
plt.title("Scatter Plot Example")
plt.xlabel("X-axis")
plt.ylabel("Y-axis")
plt.colorbar(label="Color Intensity")
plt.show()
```

---

# ğŸ‡ matplotlib ê¸°ë³¸ ì‚¬ìš©(4)

```py
# íˆìŠ¤í† ê·¸ë¨ (Histogram)
data = np.random.randn(1000)
plt.hist(data, bins=30, color="skyblue", edgecolor="black")
plt.title("Histogram Example")
plt.xlabel("Value")
plt.ylabel("Frequency")
plt.show()
```

---

# ê°„ë‹¨í•œ ì˜ˆì œ(Boxplot)

```py
import matplotlib.pyplot as plt
import numpy as np

np.random.seed(10)
data = np.random.randn(50) * 10  # í‰ê·  0, í‘œì¤€í¸ì°¨ 10ì„ ë”°ë¥´ëŠ” ì •ê·œë¶„í¬ ë°ì´í„°
data = np.append(data, [50, -40])  # ì´ìƒì¹˜ ì¶”ê°€

# ë°•ìŠ¤í”Œë¡¯ ê·¸ë¦¬ê¸° (ì´ìƒì¹˜ í‘œì‹œ)
plt.boxplot(data)

# ì œëª© ë° ë¼ë²¨ ì¶”ê°€
plt.title("Box Plot with Outliers")
plt.ylabel("Value")
plt.show()
```

---

# Boxplot í•´ì„ë²•

| ìš©ì–´                 | ì„¤ëª…                                                                                           |
| -------------------- | ---------------------------------------------------------------------------------------------- |
| **ìµœì†Ÿê°’ (minimum)** | ì œ1ì‚¬ë¶„ìœ„ì—ì„œ 1.5 IQRì„ ëº€ ìœ„ì¹˜                                                                |
| **ì œ1ì‚¬ë¶„ìœ„ìˆ˜ (Q1)** | ìƒìì˜ ì•„ë«ë©´ìœ¼ë¡œ 25% ìœ„ì¹˜ë¥¼ ì˜ë¯¸                                                              |
| **ì œ2ì‚¬ë¶„ìœ„ìˆ˜ (Q2)** | ìƒìì˜ ë‚´ë¶€ ì„ ìœ¼ë¡œ í‘œí˜„í•˜ëŠ” ì¤‘ì•™ê°’(median)ìœ¼ë¡œ 50%ì˜ ìœ„ì¹˜ë¥¼ ì˜ë¯¸                               |
| **ì œ3ì‚¬ë¶„ìœ„ìˆ˜ (Q3)** | ìƒìì˜ ìœ—ë©´ìœ¼ë¡œ 75% ìœ„ì¹˜ë¥¼ ì˜ë¯¸                                                                |
| **ìµœëŒ“ê°’ (maximum)** | ì œ3ì‚¬ë¶„ìœ„ì—ì„œ 1.5 IQRì„ ë”í•œ ìœ„ì¹˜                                                              |
| **ì‚¬ë¶„ ë²”ìœ„ (IQR)**  | Q1 ~ Q3ê¹Œì§€ ë²”ìœ„ë¥¼ ì˜ë¯¸                                                                        |
| **ìˆ˜ì—¼ (whisker)**   | ë°ì´í„°ì˜ ë²”ìœ„ë¥¼ í‘œì‹œí•˜ê¸° ìœ„í•´ ìƒì ê°€ì¥ìë¦¬ì—ì„œ ìˆ˜ì—¼ì´ ë»—ì–´ ìˆìŒ                               |
| **ì´ìƒì  (outlier)** | ìµœëŒ€ê°’ê³¼ ìµœì†Ÿê°’ì„ ë„˜ì–´ê°€ëŠ” ìœ„ì¹˜ë¥¼ ì˜ë¯¸, ì´ìƒê°’(ì¡´ì¬í•˜ëŠ” ê²½ìš°)ì€ ìˆ˜ì—¼ ë„ˆë¨¸ì— ìˆëŠ” ë°ì´í„° í¬ì¸íŠ¸ |

---

# Boxplot í•´ì„ë²•

![alt text](img/sample-3.png)

---

# Iris ë°ì´í„°ì…‹

ë¶“ê½ƒ(iris flower)í’ˆì¢… ë°ì´í„°ì…‹. í†µê³„í•™ì Ronald Fisherê°€ 1936ë…„ì— ì†Œê°œí–ˆìœ¼ë©°, ë¨¸ì‹ ëŸ¬ë‹ ë° ë°ì´í„° ë¶„ì„ì—ì„œ í…ŒìŠ¤íŠ¸ë¥¼ ëª©ì ìœ¼ë¡œ í•˜ëŠ” ëŒ€í‘œì ì¸ ë°ì´í„°ì…‹ì´ë‹¤.

|     | sepal length (cm) | sepal width (cm) | petal length (cm) | petal width (cm) | species |
| --- | ----------------- | ---------------- | ----------------- | ---------------- | ------- |
| 0   | 5.1               | 3.5              | 1.4               | 0.2              | setosa  |
| 1   | 4.9               | 3.0              | 1.4               | 0.2              | setosa  |
| 2   | 4.7               | 3.2              | 1.3               | 0.2              | setosa  |
| 3   | 4.6               | 3.1              | 1.5               | 0.2              | setosa  |
| 4   | 5.0               | 3.6              | 1.4               | 0.2              | setosa  |

---

# Iris ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°

```py
from sklearn.datasets import load_iris
import pandas as pd

# ì•„ì´ë¦¬ìŠ¤ ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°
iris = load_iris()

# ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
df = pd.DataFrame(iris.data, columns=iris.feature_names)
df['species'] = iris.target  # í’ˆì¢… ì¶”ê°€
df['species'] = df['species'].map({0: 'setosa', 1: 'versicolor', 2: 'virginica'})  # ë¼ë²¨ì„ í’ˆì¢… ì´ë¦„ìœ¼ë¡œ ë³€í™˜

# ë°ì´í„° í™•ì¸
df.head(5)
```

---

<style scoped>section{text-align: center;}</style>

# ë¶„ë¥˜

<br/>

## K-Nearest Neighbors, KNN

---

# KNN

`ìµœê·¼ì ‘ ì´ì›ƒ(K-Nearest Neighbors, KNN) ì•Œê³ ë¦¬ì¦˜`

**KNN ì•Œê³ ë¦¬ì¦˜**

1. ìƒˆë¡œìš´ ë°ì´í„° í¬ì¸íŠ¸ê°€ ì£¼ì–´ì§€ë©´, ê¸°ì¡´ ë°ì´í„°ì—ì„œ ê°€ì¥ ê°€ê¹Œìš´ Kê°œì˜ ë°ì´í„° í¬ì¸íŠ¸ë¥¼ ì°¾ëŠ”ë‹¤.
2. ì°¾ì€ Kê°œì˜ ë°ì´í„° ì¤‘ ê°€ì¥ ë§ì´ ë“±ì¥í•œ í´ë˜ìŠ¤(í’ˆì¢…)ë¥¼ ì„ íƒí•˜ì—¬ ìƒˆë¡œìš´ ë°ì´í„°ì˜ í´ë˜ìŠ¤ë¡œ ê²°ì •í•œë‹¤.
3. Kì˜ ê°’ì´ ì‘ì„ìˆ˜ë¡(ì˜ˆ: K=1), ê°œë³„ ë°ì´í„°ì— ì˜í–¥ì„ ë§ì´ ë°›ê³ , í´ìˆ˜ë¡(ì˜ˆ: K=10) ì „ì²´ì ì¸ ê²½í–¥ì„ ë”°ë¥´ê²Œ ëœë‹¤.

---

# KNN

![alt text](img/image-5.png)

---

# KNN

```py
# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
```

---

# KNN

```py
# 1ï¸âƒ£ ì•„ì´ë¦¬ìŠ¤ ë°ì´í„° ë¡œë“œ
iris = load_iris() # 150ê°œ
X = iris.data  # íŠ¹ì§• ë°ì´í„° (ê½ƒë°›ì¹¨, ê½ƒìì˜ ê¸¸ì´ì™€ ë„ˆë¹„)
y = iris.target  # í’ˆì¢… (0: Setosa, 1: Versicolor, 2: Virginica)

# 2ï¸âƒ£ ë°ì´í„° ë¶„í•  (í›ˆë ¨ ë°ì´í„° 80%, í…ŒìŠ¤íŠ¸ ë°ì´í„° 20%)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 3ï¸âƒ£ ë°ì´í„° ìŠ¤ì¼€ì¼ë§ (KNNì€ ê±°ë¦¬ ê¸°ë°˜ ì•Œê³ ë¦¬ì¦˜ì´ë¯€ë¡œ ì •ê·œí™” í•„ìˆ˜)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# 4ï¸âƒ£ KNN ëª¨ë¸ í•™ìŠµ (K=5)
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)
```

---

# KNN

```py
# 5ï¸âƒ£ ì˜ˆì¸¡ ë° í‰ê°€
y_pred = knn.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"KNN ì •í™•ë„: {accuracy:.4f}")

# 6ï¸âƒ£ ìƒ˜í”Œ ë°ì´í„° ì˜ˆì¸¡ (ìƒˆë¡œìš´ ë¶“ê½ƒ ë°ì´í„° ì…ë ¥)
new_sample = np.array([[5.1, 3.5, 1.4, 0.2]])  # Setosaì™€ ìœ ì‚¬í•œ ë°ì´í„°
new_sample_scaled = scaler.transform(new_sample)
predicted_class = knn.predict(new_sample_scaled)
print(f"ì˜ˆì¸¡ëœ í’ˆì¢…: {iris.target_names[predicted_class][0]}")

```

---

KNNì€ ë¹„ì§€ë„ í•™ìŠµ ì•„ë‹ˆì—ˆìŒ?

`ë°ì´í„° ìŠ¤ì¼€ì¼ê³¼ í•™ìŠµ ê³¼ì •ì˜ í•„ìš”ì„±`

ê±°ë¦¬ ê³„ì‚°ì—ì„œ ê° íŠ¹ì§•(feature)ì˜ ë‹¨ìœ„ë‚˜ ë²”ìœ„ê°€ ë‹¤ë¥´ë©´, í° ê°’ì„ ê°€ì§„ íŠ¹ì„±ì´ ê±°ë¦¬ ê³„ì‚°ì— ë” í° ì˜í–¥ì„ ë¯¸ì¹œë‹¤. ì˜ˆë¥¼ ë“¤ì–´, í•˜ë‚˜ì˜ íŠ¹ì„±ì€ `0`~`1` ë²”ìœ„ì´ê³  ë‹¤ë¥¸ íŠ¹ì„±ì€ `1,000`~`10,000` ë²”ìœ„ì¼ ê²½ìš°, ê±°ë¦¬ëŠ” ë‘ ë²ˆì§¸ íŠ¹ì„±ì— ë” í¬ê²Œ ì˜í–¥ì„ ë°›ì„ ìˆ˜ ìˆê¸°ì— ì •ê·œí™”ë¥¼ í•˜ê³  ê·¸ì— ë”°ë¥¸ ì í•©í•œ ì˜ˆì¸¡ ëª¨ë¸ì„ ë§Œë“œëŠ” ê²ƒ.

**ì˜ˆì‹œ**

íŠ¹ì„± 1: ê½ƒë°›ì¹¨ì˜ ê¸¸ì´ (cm) â†’ 0~10 ë²”ìœ„
íŠ¹ì„± 2: ê½ƒìì˜ ë„ˆë¹„ (cm) â†’ 0~5 ë²”ìœ„

---

#### ë°ì´í„° ìŠ¤ì¼€ì¼ë§ ê³µì‹

ìŠ¤ì¼€ì¼ë§ì„ í•˜ëŠ” ë°©ë²•ì€ ì—¬ëŸ¬ ê°€ì§€ê°€ ìˆì§€ë§Œ ê°€ì¥ í”í•˜ê²Œ ì‚¬ìš©ë˜ëŠ” ë°©ë²•ì€ **í‘œì¤€í™”(Standardization)**. ë°ì´í„°ë¥¼ í‰ê·  0, í‘œì¤€í¸ì°¨ 1ë¡œ ë³€í™˜í•˜ì—¬ ìŠ¤ì¼€ì¼ë§ì„ ì§„í–‰í•˜ë©°, ëª¨ë“  íŠ¹ì„±ì´ ë™ì¼í•œ ë²”ìœ„ì— ë“¤ì–´ê°€ ë°ì´í„° ê°„ ì˜í–¥ë ¥ì˜ ê· í˜•ì„ ë§ì¶˜ë‹¤.

**í‘œì¤€í™” (Standardization)**

$$Z = \frac{X - \mu}{\sigma} $$

- `X`: ì›ë³¸ ë°ì´í„°
- `Î¼`: í‰ê· 
- `ğœ`: í‘œì¤€í¸ì°¨

---

#### ê±°ë¦¬ ê³„ì‚°(ìœ í´ë¦¬ë“œ ê±°ë¦¬)

Nì°¨ì›ìœ¼ë¡œ ì¼ë°˜í™”ëœ ë°ì´í„°ì— ëŒ€í•´ ë‘ ì  P1(x_1, x_2, ..., x_n)ê³¼ P2(y_1, y_2, ..., y_n) ì‚¬ì´ì˜ ê±°ë¦¬

**2ì°¨ì›**

$$d(P_1, P_2) = \sqrt{(x_1 - x_2)^2 + (y_1 - y_2)^2}$$

**Nì°¨ì›**

$$d(P_1, P_2) = \sqrt{\sum_{i=1}^{n} (x_{i} - y_{i})^2}$$

---

<style scoped>section{text-align: center;}</style>

# êµ°ì§‘í™”

<br/>

## K-means ì•Œê³ ë¦¬ì¦˜

---

# K-means

`K-means ì•Œê³ ë¦¬ì¦˜`

**K-means ì•Œê³ ë¦¬ì¦˜**

1. ì£¼ì–´ì§„ ë°ì´í„°ì…‹ì—ì„œ Kê°œì˜ êµ°ì§‘ì„ ì°¾ëŠ” ì•Œê³ ë¦¬ì¦˜.
2. ì²˜ìŒ Kê°œì˜ ì¤‘ì‹¬ì ì„ ëœë¤ìœ¼ë¡œ ì„ íƒí•˜ê³ , ê° ë°ì´í„° í¬ì¸íŠ¸ë¥¼ ê°€ì¥ ê°€ê¹Œìš´ ì¤‘ì‹¬ì ì— í• ë‹¹.
3. ê° êµ°ì§‘ì— ì†í•˜ëŠ” ë°ì´í„° í¬ì¸íŠ¸ë“¤ì˜ í‰ê· ì„ ê³„ì‚°í•˜ì—¬ ìƒˆë¡œìš´ ì¤‘ì‹¬ì ì„ ê°±ì‹ .
4. êµ°ì§‘ ì¤‘ì‹¬ì ì´ ë” ì´ìƒ ë³€í•˜ì§€ ì•Šê±°ë‚˜ `ì¼ì • ê¸°ì¤€ì„ ë§Œì¡±í•  ë•Œ`ê¹Œì§€ 2ë‹¨ê³„ì™€ 3ë‹¨ê³„ë¥¼ ë°˜ë³µ.

---

# K-means

![height:500](img/image-6.png)

---

# K-means

```py
from sklearn import datasets
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

# 1ï¸âƒ£ ì•„ì´ë¦¬ìŠ¤ ë°ì´í„°ì…‹ ë¡œë“œ
iris = datasets.load_iris()

# 2ï¸âƒ£ ê½ƒìì˜ ê¸¸ì´ì™€ ë„ˆë¹„ íŠ¹ì„±ë§Œ ì¶”ì¶œ
X = iris.data[:, 2:]  # ê½ƒì ê¸¸ì´ì™€ ê½ƒì ë„ˆë¹„
y = iris.target  # ì‹¤ì œ í’ˆì¢… ì •ë³´
```

---

# K-Means

```py
# 3ï¸âƒ£ K-Means í´ëŸ¬ìŠ¤í„°ë§ ëª¨ë¸ ìƒì„± (3ê°œì˜ í´ëŸ¬ìŠ¤í„°ë¡œ ì„¤ì •)
kmeans = KMeans(n_clusters=3, random_state=21)  # n_clusters=3ì€ 3ê°œì˜ êµ°ì§‘ìœ¼ë¡œ ë¶„í• 
kmeans.fit(X)  # KMeans ëª¨ë¸ í•™ìŠµ

# 4ï¸âƒ£ ì˜ˆì¸¡ëœ í´ëŸ¬ìŠ¤í„° ë ˆì´ë¸”
y_pred = kmeans.labels_  # KMeans ì•Œê³ ë¦¬ì¦˜ì´ ì˜ˆì¸¡í•œ í´ëŸ¬ìŠ¤í„° ë ˆì´ë¸”

# 5ï¸âƒ£ êµ°ì§‘ì˜ ì¤‘ì‹¬ì  ì¶”ì¶œ
centers = kmeans.cluster_centers_  # êµ°ì§‘ ì¤‘ì‹¬ì 

# 6ï¸âƒ£ ì‹¤ì œì™€ KMeans ì˜ˆì¸¡ ê²°ê³¼ ë¹„êµ ê·¸ë˜í”„ ìƒì„±
fig, axes = plt.subplots(1, 2, figsize=(7, 3))  # ë‘ ê°œì˜ ì„œë¸Œ í”Œë¡¯
```

---

# K-Means

```py
# 7ï¸âƒ£ ì‹¤ì œ ì•„ì´ë¦¬ìŠ¤ ë°ì´í„° ì‚°ì ë„
axes[0].scatter(X[:, 0], X[:, 1], c=y, cmap='Set1_r', s=10)  # ì‹¤ì œ í’ˆì¢… ë ˆì´ë¸”ì— ë”°ë¥¸ ìƒ‰ìƒ
axes[0].set_xlabel('Petal length')  # xì¶• ë¼ë²¨
axes[0].set_ylabel('Petal width')  # yì¶• ë¼ë²¨
axes[0].set_title('Actual')  # ì œëª©: ì‹¤ì œ ê°’

# 8ï¸âƒ£ K-Means ì˜ˆì¸¡ ê²°ê³¼ ì‚°ì ë„
axes[1].scatter(X[:, 0], X[:, 1], c=y_pred, cmap='Set1', s=10)  # KMeans ì˜ˆì¸¡ê°’ì— ë”°ë¥¸ ìƒ‰ìƒ
axes[1].set_xlabel('Petal length')  # xì¶• ë¼ë²¨
axes[1].set_ylabel('Petal width')  # yì¶• ë¼ë²¨
axes[1].set_title('Predicted')  # ì œëª©: KMeans ì˜ˆì¸¡ ê°’
```

---

# K-Means

```py
# 9ï¸âƒ£ êµ°ì§‘ì˜ ì¤‘ì‹¬ì  í‘œì‹œ
axes[1].scatter(centers[:, 0], centers[:, 1], c='blue', marker='x', s=50, label='Centroids')  # êµ°ì§‘ ì¤‘ì‹¬ì 
axes[1].legend()  # ë²”ë¡€ í‘œì‹œ

# 10ï¸âƒ£ ê·¸ë˜í”„ ì¶œë ¥
plt.tight_layout()  # ê·¸ë˜í”„ ê°„ê²© ì¡°ì •
plt.show()
```

---

# ê´€ë ¨ ê³µì‹

1. K-meansì—ì„œ ë°ì´í„° í¬ì¸íŠ¸ xì™€ ì¤‘ì‹¬ì  cê°„ì˜ ê±°ë¦¬ëŠ” **ìœ í´ë¦¬ë“œ ê±°ë¦¬**ë¡œ ê³„ì‚°.

2. ê° ë°ì´í„° í¬ì¸íŠ¸`x_i`ëŠ” ê°€ì¥ ê°€ê¹Œìš´ í´ëŸ¬ìŠ¤í„° ì¤‘ì‹¬ `c_k`ë¡œ í• ë‹¹. ê° ë°ì´í„° í¬ì¸íŠ¸ì™€ ëª¨ë“  í´ëŸ¬ìŠ¤í„° ì¤‘ì‹¬ ì‚¬ì´ì˜ ê±°ë¦¬ë¥¼ ê³„ì‚° í›„ ìµœì†Œ ê±°ë¦¬ë¥¼ ê°€ì§„ í´ëŸ¬ìŠ¤í„°ë¥¼ ì„ íƒ.

$$
y_i = \underset{k}{\arg \min} \, d(x_i, c_k)
$$

3. ê° í´ëŸ¬ìŠ¤í„°ì˜ ì¤‘ì‹¬ì  `c_k`ëŠ” í•´ë‹¹ í´ëŸ¬ìŠ¤í„°ì— í• ë‹¹ëœ ëª¨ë“  ë°ì´í„° í¬ì¸íŠ¸ë“¤ì˜ í‰ê· ìœ¼ë¡œ ì—…ë°ì´íŠ¸.

$$
c_k = \frac{1}{|S_k|} \sum_{i \in S_k} x_i
$$

- `|S_k|`: í´ëŸ¬ìŠ¤í„° \( k \)ì— í• ë‹¹ëœ ë°ì´í„° í¬ì¸íŠ¸ì˜ ìˆ˜
- `S_k`: í´ëŸ¬ìŠ¤í„° \( k \)ì— ì†í•œ ë°ì´í„° í¬ì¸íŠ¸ë“¤

---

# ê´€ë ¨ ê³µì‹

4. í´ëŸ¬ìŠ¤í„° ë‚´ì˜ ë°ì´í„° í¬ì¸íŠ¸ ê°„ ê±°ë¦¬ í•©ì„ ë‚´ë¶€ ì‘ì§‘ë„(Within-cluster sum of squares, `WCSS`)ë¼ê³  ë¶€ë¥´ë©° ì´ë¥¼ ìµœì í™”í•˜ëŠ”ê²ƒì´ ìµœì¢… ëª©í‘œ. K-means ì•Œê³ ë¦¬ì¦˜ì€ ì´ ê°’ì„ ë°˜ë³µì ìœ¼ë¡œ ìµœì†Œí™”í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ ì§„í–‰.

$$
WCSS = \sum_{k=1}^{K} \sum_{x_i \in S_k} d(x_i, c_k)^2
$$

- `K`: í´ëŸ¬ìŠ¤í„°ì˜ ê°œìˆ˜
- `S_k`: í´ëŸ¬ìŠ¤í„° kì— í• ë‹¹ëœ ë°ì´í„° í¬ì¸íŠ¸
- `c_k`: í´ëŸ¬ìŠ¤í„° kì˜ ì¤‘ì‹¬

---

<style scoped>section{text-align: center;}</style>

# ì˜ˆì¸¡

<br/>

## Linear Regression (ì„ í˜• íšŒê·€)

---

# ì„ í˜• íšŒê·€

`í†µê³„í•™ê³¼ ë¨¸ì‹ ëŸ¬ë‹ì—ì„œ ê°€ì¥ ê¸°ë³¸ì ì¸ ì˜ˆì¸¡ ëª¨ë¸`

> ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ ì„¤ëª…í•˜ê¸° ê°€ì¥ ì í•©í•œ ì§ì„ ì˜ ë°©ì •ì‹ì„ ì°¾ì•„ ë°ì´í„°ë¥¼ ì„¤ëª…í•˜ê±°ë‚˜ ì˜ˆì¸¡

![height:380](img/image-7.png)

---

# ìµœì†Œì œê³±ë²•

ë°ì´í„° í¬ì¸íŠ¸ì™€ íšŒê·€ì„ (ëª¨ë¸) ê°„ì˜ ì˜¤ì°¨ë¥¼ ìµœì†Œí™”í•˜ëŠ” ë°©ë²•. ì„ í˜• íšŒê·€ì—ì„œëŠ” ê° ë°ì´í„° í¬ì¸íŠ¸ì— ëŒ€í•´ ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œ ê°’ ì‚¬ì´ì˜ ì°¨ì´ë¥¼ ì˜¤ì°¨ë¼ê³  í•˜ë©° ì´ ì˜¤ì°¨ì˜ ì œê³±ì„ ëª¨ë‘ ë”í•œ ê°’ì„ ìµœì†Œí™”í•˜ëŠ” ê²ƒì´ ëª©í‘œ.

$$
RSS = \sum_{i=1}^{n} (y_i - (\beta_0 + \beta_1 x_i))^2
$$

- `y_i`: ì‹¤ì œ ë°ì´í„° ê°’
- `Î²_0`: ì ˆí¸ (intercept)
- `Î²_1`: ê¸°ìš¸ê¸° (slope)
- `x_i`: ë…ë¦½ ë³€ìˆ˜ì˜ ê°’
- `n`: ë°ì´í„°ì˜ ê°œìˆ˜

---

# ì£¼ê°€ ì˜ˆì¸¡ ì‹¤ìŠµ

colabì—ì„œ ì§„í–‰

#### í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë‹¤ìš´ë¡œë“œ

```py
!pip install yfinance --upgrade --no-cache-dir
!pip install matplotlib
!pip install scikit-learn
```

---

# ì£¼ê°€ ì˜ˆì¸¡ ì‹¤ìŠµ

```py
import yfinance as yf
import pandas as pd

stock_data = yf.download('AAPL', start='2020-01-01', end='2025-01-01') # ì• í”Œ
stock_data.head()
```

---

# ì£¼ê°€ ì˜ˆì¸¡ ì‹¤ìŠµ

```py
import numpy as np
from sklearn.linear_model import LinearRegression
import matplotlib.pyplot as plt

# ë‚ ì§œë¥¼ ìˆ«ìë¡œ ë³€í™˜ (ë‹¨ìˆœíˆ ë‚ ì§œë¥¼ 'ì¼'ë¡œ ì²˜ë¦¬)
stock_data['Date'] = stock_data.index
stock_data['Date'] = stock_data['Date'].map(pd.Timestamp.toordinal)

# ì¢…ê°€ì™€ ë‚ ì§œ ë°ì´í„° ì¤€ë¹„
X = stock_data['Date'].values.reshape(-1, 1)  # ë…ë¦½ ë³€ìˆ˜: ë‚ ì§œ
y = stock_data['Close'].values  # ì¢…ì† ë³€ìˆ˜: ì¢…ê°€

# ì„ í˜• íšŒê·€ ëª¨ë¸ í•™ìŠµ
model = LinearRegression()
model.fit(X, y)
```

---

# ì£¼ê°€ ì˜ˆì¸¡ ì‹¤ìŠµ

```py
# ì˜ˆì¸¡í•  ë¯¸ë˜ ë‚ ì§œ ìƒì„± (ì˜ˆì‹œë¡œ 2023ë…„ 12ì›” 31ì¼ê¹Œì§€)
future_dates = pd.date_range(start='2020-01-01', periods=365*7, freq='D')
future_dates_ordinal = future_dates.map(pd.Timestamp.toordinal).values.reshape(-1, 1)

# ì˜ˆì¸¡ ê²°ê³¼
predictions = model.predict(future_dates_ordinal)

# ì˜ˆì¸¡ëœ ê°’ê³¼ ì‹¤ì œ ê°’ì„ ë¹„êµí•˜ê¸° ìœ„í•œ ì‹œê°í™”
plt.figure(figsize=(10, 6))
plt.plot(stock_data.index, stock_data['Close'], label='Actual', color='blue')  # ì‹¤ì œ ì¢…ê°€
plt.plot(future_dates, predictions, label='Predicted', color='red')  # ì˜ˆì¸¡ ì¢…ê°€
plt.xlabel('Date')
plt.ylabel('Close Price')
plt.title('Stock Price Prediction using Linear Regression')
plt.legend()
plt.grid(True)
plt.show()
```

---

# ê²°ê³¼

![height:430](img/image-8.png)

---

# ì§ì ‘ í•´ë³´ì

NVIDIA: NVDA
Tesla: TSLA
Microsoft: MSFT
Amazon: AMZN
Google (Alphabet Inc.): GOOGL (Class A) ë˜ëŠ” GOOG (Class C)
Meta (Facebook): META
Netflix: NFLX
Intel: INTC
Berkshire Hathaway: BRK-B
